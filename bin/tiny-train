#!/usr/bin/env python3

import os
import sys

# [DEBUG]
#if len(sys.argv) != 2 and len(sys.argv) != 3:
#    print(f'usage: {os.path.basename(sys.argv[0])} <pf-files> [ <cf-files> ]', file=sys.stderr)
#    sys.exit(1)
#PF_FILES = sys.argv[1].split(':')
#CF_FILES = sys.argv[2].split(':') if len(argv) > 2 else None
PF_FILES = ['../run/example.gz']
CF_FILES = None

# [TODO] Support data after ParT.
if CF_FILES is not None:
    raise NotImplemented('expect not CF_FILES yet')

main_path = os.path.join(os.path.dirname(__file__), '..')
sys.path.insert(0, os.path.join(main_path, 'src/python3'))

import numpy as np
import time
import math
import tiny
import adjet
import torch
import logging
import functools

logging.basicConfig(level=logging.INFO)

# Configuration and utilities functions.
tiny.device = 'cpu'
#tiny.device = 'cuda:0'
dtype = torch.float32
create_tensor = functools.partial(torch.tensor, dtype=dtype, device=tiny.device)
nodename = os.popen('uname -n').read().strip() or 'anonymous'
timestamp = str(int(time.time()))
model_directory = os.path.abspath(os.path.join(main_path, 'run', 'tiny', '%s-%s' % (nodename, timestamp)))
print('model directory: %s' % model_directory)
os.makedirs(model_directory)

def split_training_validation(x, validation_ratio):
    num = x.shape[0]
    num_validation = int(math.ceil(num * validation_ratio))
    num_training = num - num_validation
    return x[:num_training], x[num_training:]

# Model, loss function, and optimizer.
model = tiny.TinyBinaryClassifier(adjet.NFEAT_JET - 1)  # without label
loss_func = torch.nn.functional.binary_cross_entropy
optimizer = torch.optim.Adam(model.parameters())

# Data for training and validation.
training = []
validation = []
for (i, PF_FILE) in enumerate(PF_FILES):
    data = adjet.load_pf(PF_FILE).data[:,:adjet.NFEAT_JET]
    t, v= split_training_validation(data, 0.2)
    print('loading %s: training=%05d validation=%05d' % (PF_FILE, t.shape[0], v.shape[0]))
    training.append(t); validation.append(v)
training, validation = map(np.concatenate, (training, validation))
print('total loaded: training=%05d validation=%05d' % (training.shape[0], validation.shape[0]))
training_input, training_label = training[:,:-1], training[:,-1:].astype('bool')
training_input, training_label = map(create_tensor, (training_input, training_label))
validation_input, validation_label = validation[:,:-1], validation[:,-1:].astype('bool')
validation_input, validation_label = map(create_tensor, (validation_input, validation_label))

def train_one_epoch(epoch_id):
    optimizer.zero_grad()

    model.train()
    training_output = model(training_input)
    training_loss = loss_func(training_output, training_label)
    training_acc = ((training_output > 0.5) == training_label).to(dtype).mean()
    training_loss.backward()
    optimizer.step()

    model.eval()
    with torch.no_grad():
        validation_output = model(validation_input)
        validation_loss = loss_func(validation_output, validation_label)
        validation_acc = ((validation_output > 0.5) == validation_label).to(dtype).mean()
    print('Epoch %03d: training_loss=%.3f training_acc=%.3f validation_loss=%.3f validation_acc=%.3f'
          % (epoch_id, training_loss, training_acc, validation_loss, validation_acc))
    torch.save(model.state_dict(), os.path.join(model_directory, '%03d' % epoch_id))

for epoch_id in range(100):
    train_one_epoch(epoch_id)
