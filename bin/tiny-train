#!/usr/bin/env python3

import os
import sys
import time

main_path = os.path.join(os.path.dirname(__file__), '..')
sys.path.insert(0, os.path.join(main_path, 'src/python3'))

if len(sys.argv) < 2 or len(sys.argv) > 5:
    print(f'usage: {os.path.basename(sys.argv[0])} <pf-files> [ <cf-files> ] [ <model-dir> ] [ <device> ]', file=sys.stderr)
    sys.exit(1)
PF_FILES = sys.argv[1].split(':')
CF_FILES = sys.argv[2].split(':') if len(sys.argv) > 2 and sys.argv[2] != '-' else None
MODEL_DIR = sys.argv[3] if len(sys.argv) > 3 and sys.argv[3] != '-' else \
        os.path.abspath(os.path.join(main_path, 'run', 'tiny', '%s-%d' % (
            os.popen('uname -n').read().strip() or 'anonymous', int(time.time()),
        )))
os.makedirs(MODEL_DIR)
DEVICE = sys.argv[4] if len(sys.argv) > 4 and sys.argv[4] != '-' else None

# [TODO] Support data after ParT.
if CF_FILES is not None:
    raise NotImplemented('expect not CF_FILES yet')

import tiny
import adjet
import math
import numpy as np
import torch
import logging
import functools

logging.basicConfig(level=logging.DEBUG)

# Configuration.
if DEVICE is not None: tiny.device = DEVICE
create_tensor = functools.partial(torch.tensor, dtype=torch.float32, device=tiny.device)

def split_training_validation(x, validation_ratio):
    num = x.shape[0]
    num_validation = int(math.ceil(num * validation_ratio))
    num_training = num - num_validation
    return x[:num_training], x[num_training:]

# Model, loss function, and optimizer.
model = tiny.TinyBinaryClassifier(adjet.NFEAT_JET - 1)  # without label
loss_func = torch.nn.functional.binary_cross_entropy
optimizer = torch.optim.Adam(model.parameters())

# Data for training and validation.
training = []
validation = []
for (i, PF_FILE) in enumerate(PF_FILES):
    data = adjet.load_pf(PF_FILE).data[:,:adjet.NFEAT_JET]
    print('loading %s' % PF_FILE)
    t, v= split_training_validation(data, 0.2)
    print('splitting %s: training=%05d validation=%05d' % (PF_FILE, t.shape[0], v.shape[0]))
    training.append(t); validation.append(v)
training, validation = map(np.concatenate, (training, validation))
print('total loaded: training=%05d validation=%05d' % (training.shape[0], validation.shape[0]))
training_input, training_label = training[:,:-1], training[:,-1:].astype('bool')
training_input, training_label = map(create_tensor, (training_input, training_label))
validation_input, validation_label = validation[:,:-1], validation[:,-1:].astype('bool')
print('data loaded to main memory successfully')
validation_input, validation_label = map(create_tensor, (validation_input, validation_label))
print('data copied to GPU memory successfully')

def train_one_epoch(epoch_id):
    optimizer.zero_grad()

    model.train()
    training_output, training_loss, training_acc = model.run(training_input, training_label, loss_func)
    training_loss.backward()
    optimizer.step()

    model.eval()
    with torch.no_grad():
        validation_output, validation_loss, validation_acc = model.run(validation_input, validation_label, loss_func)

    print('Epoch %03d: training_loss=%.3f training_acc=%.3f validation_loss=%.3f validation_acc=%.3f'
          % (epoch_id, training_loss, training_acc, validation_loss, validation_acc))
    torch.save(model.state_dict(), os.path.join(MODEL_DIR, '%03d' % epoch_id))

for epoch_id in range(100):
    train_one_epoch(epoch_id)
